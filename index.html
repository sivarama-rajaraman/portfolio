<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>Sivarama Krishnan Rajaraman</title>
    <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
    <!-- Font Awesome icons (free version)-->
    <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet"
        type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
</head>

<body id="page-top">
    <!------------------------------ Navigation --------------------------->
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">
            <span class="d-block d-lg-none">Sivarama Krishnan Rajaraman</span>
            <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2"
                    src="assets/img/profile.jpeg" alt="" /></span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span
                class="navbar-toggler-icon"></span></button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#execu-summary">Executive Summary</a>
                </li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Experience</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#tech-summary">Technical Summary</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#research-interests">Research Interests</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#research-experience">Research
                        Experience</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#global-interaction">Global
                        Interaction</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#training-certification">Training courses and certifications</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#editorial-pos">Editorial Board Positions</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#reviewer-pos">Reviewer Positions</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#presentations">Presentations</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#mentoring">Mentoring and extra-curricular activities</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications ">Publications</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#references ">References</a></li>
            </ul>
        </div>
    </nav>
    <!-- Page Content-->
    <div class="container-fluid p-0">
        <!--------------------------- About ------------------------------->
        <section class="resume-section" id="about">
            <div class="resume-section-content">
                <h1 class="mb-0">
                    Sivarama Krishnan Rajaraman
                </h1>
                <div class="subheading">Medical Imaging Deep Learning Research Scientist</div>
                <div class="subheading">National Library of Medicine, National Institutes of Health</div>
                <div class="subheading mb-5">
                    8600 Rockville Pike, Bethesda, MD 20894· (301)-827-2383.
                    <a href="mailto:name@email.com">sivaramakrishnan.rajaraman@nih.gov</a>
                </div>
                <div class="social-icons">
                    <a class="social-icon" href="https://www.linkedin.com/in/sivaramakrishnan-rajaraman-28202a45"><i
                            class="fab fa-linkedin-in"></i></a>
                    <a class="social-icon" href="https://github.com/sivaramakrishnan-rajaraman"><i
                            class="fab fa-github"></i></a>
                    <a class="social-icon" href="https://twitter.com/raaju_shiv"><i class="fab fa-twitter"></i></a>
                    <a class="social-icon" href="https://www.facebook.com/siva.rajaraman.7"><i
                            class="fab fa-facebook-f"></i></a>
                </div>
            </div>
        </section>
        <hr class="m-0" />
        <!--------------------------- Executive Summary ------------------->
        <section class="resume-section" id="execu-summary">
            <div class="resume-section-content">
                <h2 class="mb-5">Executive Summary</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <p>Dr. Sivarama Krishnan Rajaraman holds the position of Deep Learning Research Scientist at the
                            Lister Hill National Center for Biomedical Communications, U. S. National Institutes of
                            Health. Dr. Rajaraman received his Ph.D. in Information and Communication engineering from
                            Anna University, India. At the U. S. National Library of Medicine, he pursued his
                            postdoctoral studies that involved R&D projects in medical image analysis toward developing
                            robust, cost-effective solutions for clinical decision-making. These projects apply
                            computational sciences and engineering methods toward advancing life science applications
                            and aid healthcare professionals in low-cost, high-quality decision-making at the point of
                            care screening/diagnostics. He is a versatile researcher with expertise in machine learning,
                            particularly deep learning, biomedical image analysis/understanding, and computer vision. 
                            He has more than 15 years of experience in academia where he taught core and allied subjects 
                            in biomedical engineering. He has authored several national and international journal and 
                            conference publications in his area of expertise. Dr. Rajaraman is a Life Member of the 
                            Society of Photo-optical Instrumentation Engineers (SPIE), a regular member of the Institute 
                            of Electrical and Electronics Engineers (IEEE), IEEE Engineering in Medicine & Biology Society (EMBS), 
                            and the Biomedical Engineering Society (BMES).

                        </p>
                    </div>
                </div>


            </div>
        </section>
        <hr class="m-0" />

        <!--------------------------- Education ---------------------------->
        <section class="resume-section" id="education">
            <div class="resume-section-content">
                <h2 class="mb-5">Education</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">PSNACET, Madurai Kamaraj University, Madurai, India</h3>
                        <div class="subheading mb-3">B.E</div>
                        <div>Electronics and Communication Eng.</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">2001</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">College of Engineering, Chennai, India</h3>
                        <div class="subheading mb-3">M.E.</div>
                        <div>Medical Electronics</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">2006</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Anna University, Chennai, India</h3>
                        <div class="subheading mb-3">Ph.D.</div>
                        <div>Information and Communication Eng.</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">2015</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">National Library of Medicine, National Institutes of Health</h3>
                        <div class="subheading mb-3">Postdoctoral Research</div>
                        <div>Deep Learning in biomedical Image analysis/understanding</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">2018</span></div>
                </div>
            </div>
        </section>
        <hr class="m-0" />

        <!--------------------------- Experience --------------------------->
        <section class="resume-section" id="experience">
            <div class="resume-section-content">
                <h2 class="mb-5">Experience</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Lecturer, Dept. of Electronics and Communication Eng.</h3>
                        <div class=" mb-3">PSNA College of Engineering and Technology, Dindigul, Tamil Nadu, India</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">June 2001 - May 2002</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Assistant Professor, Dept. of Electronics and Communication Eng.</h3>
                        <div class=" mb-3">Adhiparasakthi Engineering College, Melmaruvathur, Tamil Nadu, India</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">November 2002 - Jan 2008</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Assistant Professor, Dept. of Biomedical Eng.</h3>
                        <div class=" mb-3">SSN College of Engineering, Kalavakkam, Kanchipuram, Tamil Nadu, India</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">Feb 2008 - December 2015</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Associate Professor, Dept. of Biomedical Eng.</h3>
                        <div class=" mb-3">SSN College of Engineering, Kalavakkam, Kanchipuram, Tamil Nadu, India</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">Jan 2015 - Nov 2016</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Postdoctoral Researcher</h3>
                        <div class=" mb-3">National Library of Medicine, National Institutes of Health, Bethesda,
                            Maryland, USA</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">December 2016 - October 2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Medical Imaging Deep Learning Research Scientist</h3>
                        <div class=" mb-3">Medical Science & Computing, LLC, Rockville, Maryland, USA</div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary">October 2018 - Present</span></div>
                </div>
            </div>
        </section>
        <hr class="m-0" />

        <!--------------------------- Technical summary --------------------------->
        <section class="resume-section" id="tech-summary">
            <div class="resume-section-content">
                <h2 class="mb-5">Technical Summary</h2>
                <table class="table">
                    <tr>
                        <td>Programming Languages</td>
                        <td>Python</td>
                    </tr>
                    <tr>
                        <td>Scripting Languages</td>
                        <td>MATLAB</td>
                    </tr>
                    <tr>
                        <td>APIs and Libraries</td>
                        <td>OpenCV, Tensorflow, Keras, Scikit-learn</td>
                    </tr>
                    <tr>
                        <td>Operating Systems</td>
                        <td>Widows, Unix/Linux, and Google Android</td>
                    </tr>
                    <tr>
                        <td>Document Markup Language</td>
                        <td>LaTeX</td>
                    </tr>
                    <tr>
                        <td>Other Tools</td>
                        <td>Keras, Tensorflow, Weka, Microsoft Office, IBM SPSS</td>
                    </tr>
                </table>
            </div>
        </section>
        <hr class="m-0" />

        <!--------------------------- Research Interests ------------------>
        <section class="resume-section" id="research-interests">
            <div class="resume-section-content">
                <h2 class="mb-5">Research Interests</h2>

                <div class="flex-grow-1">
                    Artificial Intelligence, Computer Vision, Pattern Recognition, Machine Learning, Deep Learning,
                        Biomedical Imaging, Biomaterial-Associated Infections, Meditation.

                </div>

            </div>
        </section>
        <hr class="m-0" />

        <!--------------------------- Research Experience ------------------>
        <section class="resume-section" id="research-experience">
            <div class="resume-section-content">
                <h2 class="mb-5">Research Experience</h2>
                <div class="flex-grow-1 mb-5">
                    <h3>Project Group: Computer-Aided Population Screening Using Chest X-Rays, CEB, LHNCBC,
                        NLM</h3>
                    <div class="flex-grow-1">
                        <p> <b>Location: </b> Lister Hill National Center for Biomedical Communications, National
                            Library of Medicine,
                            National Institutes of Health, USA
                        </p>
                        <p> <b>Tools: </b> Matlab, Python, Keras DL framework with Theano/Tensorflow backend,
                            Singularity and Docker
                            containers for packaging scientific workflows, software, libraries, and data, IBM SPSS
                            version 25.0 for
                            statistical validation.
                        </p>
                        <p> <b>Computation Resources: </b> Biowulf (95,000+ core/30 PB Linux cluster) NIH high
                            performance computing
                            (HPC) facility, NVIDIA DGX-1 workstation with Ubuntu Linux host OS and V100 GPUs for
                            accelerated
                            DL applications, Windows, and Linux desktop computers with multiple NVIDIA GEFORCE GTX 1080
                            GPUs.
                        </p>
                    </div>
                    <section>
                        <h4 class="mt-5 mb-3">Project title 1: Deep Learning for population screening using chest
                            radiography
                        </h4>
                        <div class="flex-grow-1">
                            <div><b>Scientific Highlights:</b> </div>
                            <p>
                                Computer-Aided COVID-19+ Population Screening Using Chest X-Rays, CEB, LHNCBC, NLM:
                                Novel Coronavirus disease 2019 (COVID-19) is caused by the new Severe Acute Respiratory Syndrome 
                                Coronavirus 2 (SARS-CoV-2) that originated in Wuhan in the Hubei province in China and has spread 
                                worldwide. The World Health Organization (WHO) declared the outbreak a pandemic on March 11, 2020. 
                                The disease is rapidly affecting worldwide population with statistics quickly falling out of date. 
                                As of April 12, 2020, there are over 1.8 million confirmed cases reported globally with over 100,000 
                                reported deaths. Lung disease that causes difficulty in breathing has been reported as an early 
                                indicator along with hyperthermia in the COVID-19 infected population. The lung abnormalities 
                                caused by non-2019-nCOV viruses are observed as peripheral or hilar and visually similar to, 
                                yet often distinct from, viral pneumonia and other bacterial pathogens. In this project, we 
                                propose several measures to effectively detect COVID-19 disease manifestations in Chest X-rays.
                             </p>                                
                                <div><b>Related publications:</b></div>
                            <section>
                                <P>Rajaraman S, Sornapudi S, Alderson PO, Folio LR, Antani SK (2020) Analyzing inter-reader variability 
                                    affecting deep ensemble learning for COVID-19 detection in chest radiographs. 
                                    PLoS ONE 15(11): e0242301. https://doi.org/10.1371/journal.pone.0242301                                    
                                </P>
                                <p>Rajaraman S, Sornapudi S, Alderson PO, Folio LR, Antani SK. Interpreting Deep Ensemble 
                                    Learning through Radiologist Annotations for COVID-19 Detection in Chest Radiographs. 
                                    medRxiv 2020.07.15.20154385; doi: https://doi.org/10.1101/2020.07.15.20154385.
                                </p>
                                <p>Rajaraman S, Antani, S. Weakly Labeled Data Augmentation for Deep Learning: A Study on COVID-19 Detection 
                                    in Chest X-Rays. Diagnostics 2020, 10, 358.
                                </p>
                                <p>Rajaraman S, Siegelman J, Alderson PO, Folio LS, Folio LR and Antani SK, "Iteratively Pruned Deep Learning 
                                    Ensembles for COVID-19 Detection in Chest X-Rays," in IEEE Access, vol. 8, pp. 115041-115050, 2020, 
                                    doi: 10.1109/ACCESS.2020.3003810.
                                </section>
                        </div>
                    </section>
                    
                        <h4 class="mt-5 mb-3">Project title 2: Computer-Aided TB Screening for HIV+ Population Using Chest X-Rays, CEB, LHNCBC, NLM
                        </h4>
                        <div class="flex-grow-1">
                            <div><b>Scientific Highlights:</b> </div>
                            <p>
                            
                                According to the World Health Organization (WHO), tuberculosis (TB) remains the most
                                deadly
                                infectious disease in the world. Analysis of frontal chest X-rays (CXR) is one of the
                                most
                                popular
                                methods for initial TB screening, however, the method is impacted by the lack of experts
                                for
                                screening
                                chest radiographs. State-of-the-art CADx software typically is based on ML approaches
                                that
                                use
                                hand-engineered features, demanding expertise in analyzing the input variances and
                                accounting for the
                                changes in size, background, angle, and position of the region of interest (ROI) on the
                                underlying medical
                                imagery. More automatic DL tools have demonstrated promising results in a wide range of
                                ML
                                applications. Convolutional Neural Networks (CNN), a class of DL models, have gained
                                research
                                prominence in image classification, detection, and localization tasks because they are
                                highly scalable and
                                deliver superior results with end-to-end feature extraction and classification. In this
                                study, we evaluated
                                the performance of CNN based DL models for population screening using frontal CXRs. We
                                worked with
                                the public and private CXR collections, archived at NLM. We observed that CNNs are a
                                promising
                                feature extracting tool for medical imagery including the automated diagnosis of TB from
                                chest
                                radiographs but emphasized the importance of large data sets for the most accurate
                                classification. We also
                                performed Ensemble learning (EL) to construct non-linear decision making functions and
                                improve visual
                                recognition by combining multiple models toward obtaining promising predictions. EL
                                methods
                                allow
                                blending intelligence from different learning algorithms. We created a stacked ensemble
                                of
                                that worked
                                with hand-engineered and deep CNN features toward the process of improving the detection
                                accuracy to
                                advance research in TB detection. The results obtained with the stacked model ensemble
                                were
                                found to be
                                promising compared to the state-of-the-art in TB detection. Training metrics are not
                                always
                                reliable and
                                standard visualization techniques like feature and activation visualization, saliency
                                maps,
                                partial
                                occlusion measurements, and class activation maps (CAM) help in providing a sanity check
                                on
                                the
                                learning strategy. Saliency maps provide intuition of attention and help to analyze the
                                most
                                influential
                                features. Partial occlusion studies help in identifying whether the trained model is
                                actually classifying
                                based on the task-specific features and not the surrounding context and gaining a clear
                                understanding of
                                the learned behavior of the model for the underlying task. CAM helps to visualize
                                discriminative image
                                regions used by the trained model to identify an image category. We performed these
                                visualizations to
                                understand the learned parameters, model behavior and optimized the model architecture
                                and
                                hyper-parameters for improved learning.
                            </p>
                            <div><b>Related publications:</b></div>
                            <section>
                                <P>Rajaraman S, Candemir S, Xue Z, Alderson P, Kohli M, Abuya J, Thoma GR, Antani SK. A
                                    novel stacked generalization of models for improved TB detection in chest
                                    radiographs.
                                    Proc.
                                    IEEE Engineering in Medicine and Biology Conference (EMBC 2018), Honolulu, Hawaii,
                                    2018.
                                    pp. 718-721.
                                </P>
                                <p>Rajaraman S, Antani SK, Candemir S, Xue Z, Abuya J, Kohli M, Alderson P, Thoma GR.
                                    Comparing deep learning models for population screening using chest radiography.
                                    Proc.
                                    SPIE
                                    10575, Medical Imaging 2018: Computer-Aided Diagnosis, 105751E (27 February 2018).
                                </p>
                                <p>Rajaraman S, Antani SK, Xue Z, Candemir S, Jaeger S, Thoma GR. Visualizing
                                    abnormalities
                                    in chest radiographs through salient network activations in Deep Learning. Proc.
                                    IEEE
                                    Life
                                    Sciences Conference (LSC), Sydney, Australia, 2017. pp. 71-74,
                                    DOI:10.1109/LSC.2017.8268146.
                                </p>
                                <p>Rajaraman S, Candemir S, Xue Z, Alderson P, Thoma G, Antani SK. In Santosh KC et al.
                                    (Eds.). Medical Imaging: Artificial Intelligence, Image Recognition, and Machine
                                    Learning
                                    Techniques. (pp. 1-26). New York, NY: CRC Press, Taylor & Francis Group.
                                </p>
                            </section>
                        </div>
                    </section>

                    <section>
                        <h4 class="mt-5 mb-3">Project title 3: Visualization and Interpretation of Convolutional Neural
                            Network
                            Predictions in Detecting Pneumonia in Pediatric Chest Radiographs
                        </h4>
                        <div class="flex-grow-1">
                            <div><b>Scientific Highlights:</b> </div>
                            <p>Pneumonia affects 7% of the global population, resulting in 2 million pediatric deaths
                                every year.
                                Chest X-ray (CXR) analysis is routinely performed to diagnose the disease.
                                Computer-aided diagnostic
                                (CADx) tools aim to supplement decision-making. These tools process the handcrafted
                                and/or
                                convolutional neural network (CNN) extracted image features for visual recognition.
                                However, CNNs are
                                perceived as black boxes since their performance lack explanations. This is a serious
                                bottleneck in
                                applications involving medical screening/diagnosis since poorly interpreted model
                                behavior could
                                adversely affect the clinical decision. In this study, we evaluate, visualize, and
                                explain the performance of
                                customized CNNs to detect pneumonia and further differentiate between bacterial and
                                viral types in
                                pediatric CXRs. We present a novel visualization strategy to localize the region of
                                interest (ROI) that is
                                considered relevant for model predictions across all the inputs that belong to an
                                expected class. We
                                statistically validate the models’ performance toward the underlying tasks. We observe
                                that the
                                customized VGG16 model achieved better performance in detecting the disease and
                                distinguishing
                                between bacterial and viral pneumonia respectively.
                            </p>
                            <div><b>Related publications:</b></div>
                            <section>
                                <P>Rajaraman S, Candemir S, Kim I, Thoma GR, Antani SK. Visualization and Interpretation
                                    of
                                    Convolutional Neural Network Predictions in Detecting Pneumonia in Pediatric Chest
                                    Radiographs. Appl. Sci. 2018, 8, 1715.
                                </P>
                                <p>Rajaraman S, Candemir S, Thoma G, Antani S. Visualizing and explaining deep learning
                                    predictions for pneumonia detection in pediatric chest radiographs, Proc. SPIE
                                    10950, Medical
                                    Imaging 2019: Computer-Aided Diagnosis, 109500S (13 March 2019); doi:
                                    10.1117/12.2512752.
                                </p>

                            </section>
                        </div>
                    </section>

                    <section>
                        <h4 class="mt-5 mb-3">Project title 4: Investigating Deep Convolutional Neural Networks for
                            Cardiomegaly Detection in Chest X-rays
                        </h4>
                        <div class="flex-grow-1">
                            <div><b>Scientific Highlights:</b> </div>
                            <p>In this study, we investigated the usage of deep CNN models for automatic detection of
                                cardiomegaly in digital CXRs. We fine-tuned several deep CNN architectures to detect the
                                presence of
                                cardiomegaly in CXRs. Next, we introduced an alternative fine-tuning approach where we
                                first fully
                                trained an architecture with a large-scale CXR collection and fine-tuned the model with
                                cardiomegaly
                                CXRs. As test sets, we used two publicly available datasets, the NLM-Indiana Collection,
                                and the
                                NIH-CXR datasets. Based on our preliminary results, we observed the following: (a)
                                data-based approach
                                produced better results than prior rule-based approaches developed for cardiomegaly
                                detection; (b) our
                                preliminary test with alternative fine-tuning approach was promising; (iii) there was a
                                correlation between
                                the Softmax probability and severity of the disease.
                            </p>
                            <div><b>Related publications:</b></div>
                            <section>
                                <P>Candemir S, Rajaraman S, Thoma GR, Antani SK. Deep Learning for Grading Cardiomegaly
                                    Severity in Chest X-rays: An Investigation. Proc. IEEE Life Sciences Conference (LSC
                                    2018),
                                    Montreal, Quebec, Canada, 28 – 30 October 2018. pp. 109-113.
                                </P>

                            </section>
                        </div>
                    </section>

                    <section>
                        <h4 class="mt-5 mb-3">Project title 5: Gender Detection from Spine X-ray Images Using Deep
                            Learning
                        </h4>
                        <div class="flex-grow-1">
                            <div><b>Scientific Highlights:</b> </div>
                            <p>In this work, we classified the spine x-ray images according to image characteristics
                                that
                                exhibited gender. We compared classification results of customized CNNs with pre-trained
                                CNN models
                                and fine-tuned with the spine images. We developed a method for extracting the ROI in
                                the cervical spine
                                images using a content-based image retrieval method and evaluated the effect of ROI
                                cropping. We
                                verified our method using the images in the NHANES II dataset hosted by NLM.
                            </p>
                            <div><b>Related publications:</b></div>
                            <section>
                                <P>Xue Z, Rajaraman S, Long LR, Antani SK, Thoma GR. Gender Detection from Spine X-ray
                                    Images Using Deep Learning. Proc. IEEE International Symposium on Computer-Based
                                    Medical
                                    Systems (CBMS), Karlstad, Sweden, 2018. pp. 54-58, DOI:10.1109/CBMS.2018.00017.
                                </P>

                            </section>
                        </div>
                    </section>

                    <section>
                        <h4 class="mt-5 mb-3">Project title 6: Visualizing and understanding convolutional neural
                            networks
                            toward
                            multi-modality classification
                        </h4>
                        <div class="flex-grow-1">
                            <div><b>Scientific Highlights:</b> </div>
                            <p>In this study, we performed a multi-modality classification with deep CNN models. We
                                worked with 12
                                different modality images including X-rays, CT, MRI, PET, photos, illustrations, light
                                microscope,
                                electron microscope, fluorescence microscope, endoscope, fundus, and ultrasound. We
                                found the optimal
                                model through cross-validation studies and visualized the weights, activations and CAM
                                in the trained
                                model toward understanding its learning strategy. We collected data from NLM OpenI
                                ®, Cancer Imaging
                                Archive and other open-source medical image libraries.

                            </p>
                            <div><b>Related publications:</b></div>
                            <section>
                                <P>Kim I, Rajaraman, S, Antani S. Visual Interpretation of Convolutional Neural Network
                                    Predictions in Classifying Medical Image Modalities. MDPI Diagnostics 2019, 9, 38.
                                    Rajaraman S, Antani S. (2019) Visualizing Salient Network Activations in
                                    Convolutional
                                    Neural Networks for Medical Image Modality Classification. In: Santosh K., Hegadi R.
                                    (eds)
                                    Recent Trends in Image Processing and Pattern Recognition. RTIP2R 2018.
                                    Communications in
                                    Computer and Information Science, vol. 1036. Springer, Singapore. DOI:
                                    https://doi.org/10.1007/978-981-13-9184-2_4
                                </P>

                            </section>
                        </div>
                    </section>

                    <section>
                        <h4 class="mt-5 mb-3">Project title 7: Assessment of an ensemble of machine learning models
                            toward
                            abnormality detection in chest radiographs
                            multi-modality classification
                        </h4>
                        <div class="flex-grow-1">
                            <div><b>Scientific Highlights:</b> </div>
                            <p>Respiratory diseases account for the majority of deaths and disabilities across the
                                world. Chest X-ray
                                (CXR) analysis remains a common part of the protocol for confirming lung abnormalities.
                                However, the
                                ratio of expert radiologists to the radiograph volume is continuing to increase leading
                                to severe backlogs
                                and interpretation delays. These issues can be mitigated by a computer-aided diagnostic
                                (CADx) system
                                to supplement decision-making and improve throughput while preserving and possibly
                                improving the
                                standard-of-care. These systems reportedly use handcrafted features and/or data-driven
                                algorithms like
                                deep learning (DL) to learn underlying data distributions. The remarkable success of
                                convolutional neural
                                networks (CNN) toward image recognition tasks has made them a promising choice for
                                automated
                                medical image analyses. Ensemble learning combines the predictions of multiple learning
                                algorithms to
                                construct complex, non-linear functions and improve performance, robustness, and
                                generalization. This
                                study aims to construct and assess the performance of an ensemble of machine learning
                                (ML) models
                                applied to the challenge of classifying normal and abnormal CXRs and significantly
                                reducing the
                                diagnostic load of radiologists and primary-care physicians.

                            </p>
                            <div><b>Related publications:</b></div>
                            <section>
                                <P>Rajaraman S, Sornapudi S, Kohli M, Antani SK. Assessment of an ensemble of machine
                                    learning models toward abnormality detection in chest radiographs. Proc. IEEE
                                    Engineering in
                                    Medicine and Biology Conference (EMBC), Berlin, Germany, 23 – 27 July 2019. pp. 3689
                                    –
                                    3692.
                                    Rajaraman S, Antani S. A combination of multi-model knowledge transfer and ensemble
                                    learning for improved TB detection in chest radiographs. Submitted to SPIE Journal
                                    of Medical
                                    Imaging

                                </P>

                            </section>
                        </div>
                    </section>

                    <section>
                        <h4 class="mt-5 mb-3">Project title 8: Performance assessment of data augmentation techniques
                            toward
                            improving abnormality detection in chest radiographs
                        </h4>
                        <div class="flex-grow-1">
                            <div><b>Scientific Highlights:</b> </div>
                            <p>Medical imaging datasets are available in sparse due to privacy issues and the high cost
                                of annotations.
                                Data augmentation is a widely used practice in machine learning that helps in reduced
                                bias, overfitting
                                and improved model generalization. In this study, we evaluated the performance of
                                traditional
                                augmentation methods and Generative Adversarial Networks (GANs) toward synthesizing data
                                to enrich
                                training and observed for possible improvement in performance toward abnormality
                                detection in chest
                                radiographs. GANs provide an avenue to capture the biological variance in the underlying
                                image data and
                                synthesize realistic samples. We observed that the traditional data augmentation
                                strategies including
                                unsharp masking, Gaussian smoothing and minimum filtering helped in improved performance
                                by
                                mimicking the biological variance in the unseen test data and helped the model to
                                optimally converge in
                                comparison to GAN generated synthetic images.


                            </p>
                            <div><b>Related publications:</b></div>
                            <section>
                                <P>Ganesan P, Rajaraman S, Long LR, Ghoraani B, Antani SK. Assessment of Data
                                    Augmentation
                                    Strategies Toward Performance Improvement of Abnormality Classification in Chest
                                    Radiographs. Proc. IEEE Engineering in Medicine and Biology Conference (EMBC),
                                    Berlin,
                                    Germany, 23 – 27 July 2019. pp. 841 – 844.

                                </P>

                            </section>
                        </div>
                    </section>
                </div>

                <div class="flex-grow-1 mb-5">
                    <h3>Project Group: Malaria Screener, CEB, LHNCBC, NLM</h3>
                    <div class="flex-grow-1">
                        <p> <b>Location: </b> Lister Hill National Center for Biomedical Communications, National
                            Library of Medicine,
                            National Institutes of Health, USA
                        </p>
                        <p> <b>Tools: </b> Matlab, Python, Keras DL framework with Theano/Tensorflow backend,
                            Singularity and Docker
                            containers for packaging scientific workflows, software, libraries, and data, IBM SPSS
                            version 25.0 for
                            statistical validation.

                        </p>
                        <p> <b>Computation Resources: </b>Matlab, Python, Keras DL framework with Theano/Tensorflow
                            backend, Singularity and Docker
                            containers for packaging scientific workflows, software, libraries, and data, IBM SPSS
                            version 25.0 for
                            statistical validation.

                        </p>
                        <p> <b>Scientific Highlights: </b>Malaria is caused by parasites that are transmitted through
                            the bites of infected Anopheles
                            mosquitoes. With about 200 million cases worldwide and about 400,000 deaths per year,
                            malaria is a
                            major burden on global health. The current standard method for malaria diagnosis in the
                            field is light
                            microscopy of blood films. However, microscopic diagnostics is not standardized and depends
                            heavily on
                            the experience and skill of the microscopists. To improve malaria diagnostics, LHNCBC, in
                            collaboration
                            with NIH’s National Institute of Allergy and Infectious Diseases (NIAID) and Mahidol-Oxford
                            University, is developing a mobile application that runs on an Android phone for parasite
                            detection and
                            counting in blood films. Giemsa-stained thin blood smear slides from 150 P.
                            falciparum-infected and 50
                            healthy patients were collected and photographed at Chittagong Medical College Hospital,
                            Bangladesh.
                            The smartphone’s built-in camera acquired images of slides for each microscopic field of
                            view. The
                            images were manually annotated by an expert slide reader at the Mahidol-Oxford Tropical
                            Medicine
                            Research Unit in Bangkok, Thailand. The de-identified images and annotations are archived at
                            NLM. We
                            applied a level-set based algorithm to detect and segment the red blood cells. We proposed
                            the advantages
                            offered through visualizing the features and activations in customized CNNs applied to the
                            challenge of
                            malaria cell classification. We evaluated the performance of customized and pre-trained CNN
                            based DL
                            models as feature extractors toward classifying parasitized and uninfected cells to aid in
                            improved disease
                            screening. We experimentally determined the optimal model layers for feature extraction from
                            the
                            underlying data. Statistical validation of the results demonstrated the use of pre-trained
                            CNNs as a
                            promising tool for feature extraction for this purpose.
                            CNN models are perceived as black boxes since there is a lack of understanding of the
                            learned
                            behavior from the underlying task of interest. This lack of transparency is a serious
                            drawback, particularly
                            in applications involving medical screening and diagnosis since poorly understood model
                            behavior could
                            adversely impact the process of decision-making. In this study, we highlighted the
                            advantages offered
                            through visualizing and understanding the weights, saliencies, CAM and ROI localizations in
                            CNNs
                            applied to the challenge of classifying parasitized and uninfected cells to aid in malaria
                            screening. We
                            provided an explanation on what made these models arrive at the classification decision. We
                            evaluated the
                            performance of different CNNs and statistically validated with a large-scale clinical
                            dataset at the patient
                            level. We observed that CNN models could serve as a promising classification tool for this
                            purpose.

                        </p>
                        <div><b>Related publications:</b></div>
                        <section>
                            <p>Rajaraman S, Jaeger S, Antani SK. (2019) Performance evaluation of deep neural ensembles
                                toward malaria parasite detection in thin-blood smear images. PeerJ 7:e6977
                                https://doi.org/10.7717/peerj.6977.</p>

                            <p>Rajaraman S, Antani SK, Jaeger S. Visualizing Deep Learning Activations for Improved
                                Malaria Cell Classification. Proceedings of the First Workshop in Medical Informatics
                                and
                                Healthcare (MIH 2017), Proceedings of Machine Learning Research (PMLR), v. 69, p. 40-47.
                            </p>

                            <p>Rajaraman S, Antani SK, Poostchi Mohammadabadi M, Silamut K, Hossain MA, Maude RJ,
                                Jaeger S, Thoma GR. (2018) Pre-trained convolutional neural networks as feature
                                extractors
                                toward improved malaria parasite detection in thin blood smear images. PeerJ6:e4568
                                https://doi.org/10.7717/peerj.4568.</p>

                            <p>Rajaraman S, Silamut K, Hossain MA, Ersoy I, Maude RJ, Jaeger S, Thoma GR, Antani SK.
                                Understanding the learned behavior of customized convolutional neural networks toward
                                malaria
                                parasite detection in thin blood smear images. J. Med. Imag. 5(3), 034501 (2018), doi:
                                10.1117/1.JMI.5.3.034501.</p>

                        </section>
                    </div>
                </div>

                <div class="flex-grow-1 mb-5">
                    <h3>Project Group: Computer Aided Diagnosis of Skin Tumors from Dermal Images</h3>
                    <div class="flex-grow-1">

                        <p> <b>Tools: </b> Matlab, IBM SPSS version 23.0 for statistical validation </p>

                        <p> <b>Computation Resources: </b>Desktop with Windows OS. </p>

                        <p> <b>Scientific Highlights: </b>Skin tumor is the uncontrolled growth of skin cells which may
                            be cancerous. We aimed to
                            develop a CADx tool for diagnosing skin tumors. The dermal images of three types including
                            benign
                            tumor, malignant melanoma, and normal moles were collected and preprocessed to remove hair
                            cells. A
                            contour based level set technique was applied to segment the lesion. Morphological features
                            were
                            extracted and a random subset method was used to perform feature selection. The
                            classification was
                            performed using classifiers including a multi-layer perceptron and support vector machine
                            (SVM). The
                            classification accuracy was found to be 94% and 96% respectively. We statistically validated
                            the
                            performance of the classifiers using one way ANOVA and Tukey post-hoc analyses.

                        </p>
                        <div><b>Related publications:</b></div>
                        <section>
                            <p>Thamizhvani TR, Lakshmanan S, Rajaraman S. Computer Aided Diagnosis of Skin Tumours
                                from Dermal Images. Hemanth D., Smys S. (eds) Computational Vision and Bio Inspired
                                Computing. Lecture Notes in Computational Vision and Biomechanics, vol 28. Springer,
                                Cham.
                                Thamizhvani TR, Lakshmanan S, Rajaraman S. Mobile application-based computer-aided
                                diagnosis of skin tumours from dermal images, The Imaging Science Journal, 66:6,
                                382-391,
                                2018, DOI: 10.1080/13682199.2018.1492682.
                            </p>

                        </section>
                    </div>
                </div>

                <div class="flex-grow-1 mb-5">
                    <h3>Project Group: Novel Chromosomal Image Processing Techniques for Performance Enhancement of
                        Automatic Karyotyping</h3>
                    <div class="flex-grow-1">
                        <p> <b>Location: </b> Anna University, Chennai, India
                        </p>
                        <p> <b>Tools: </b> Matlab, IBM SPSS version 23.0 for statistical validation </p>

                        <p> <b>Computation Resources: </b>Desktop with Windows OS. </p>

                        <p> <b>Scientific Highlights: </b>Karyotyping is a specialized procedure that helps diagnosing
                            the genetic abnormalities and is one
                            of the fundamental techniques employed for studying the genetic information. Cytogeneticists
                            examine
                            the karyotypes to identify the presence of chromosomal pairs, and missing or rearranged
                            genetic materials
                            in the chromosomes. Automatic karyotyping packages are accounted to be 70% efficient, as
                            suggested by
                            the cytogenetic experts. However, these packages are found to have errors in counting due to
                            the presence
                            of unwanted components including stain, debris and interphase cells, chromosomal
                            misplacement,
                            chromosomal inversion and rejection that occurs due to occlusion of chromosomes. In this
                            study, we
                            attempted to resolve these limitations and improve the efficiency of automatic karyotyping
                            systems. We
                            proposed a novel, efficient method based on multi-directional block ranking to remove the
                            interphase
                            cells without affecting the metaphase spread of chromosomes. We also proposed a robust
                            algorithm based
                            on evolutionary computation methods to identify and resolve occlusion in an occluded
                            chromosomal
                            cluster. This reduced errors in an automatic karyotyping system due to incorrect
                            identification of partially
                            or totally hidden metaphase chromosomes. We also proposed a novel, efficient,
                            similarity-based classifier
                            that used only three features as used by the cytogeneticists in manual diagnosis of genetic
                            disorders. The
                            effectiveness of the work was evaluated with the standardized karyotype data obtained from
                            Center for
                            Medical Genetics, Kilpauk, Chennai, and BIOIMLAB, Laboratory of Medical Imaging, University
                            of
                            Padova, Italy

                        </p>
                        <div><b>Related publications:</b></div>
                        <section>
                            <p>Rajaraman S, Vaidyanathan G, Chokkalingam A. Performance Evaluation of Bio-Inspired
                                Optimization Algorithms in Resolving Chromosomal Occlusions. Journal of Medical Imaging
                                and health Informatics, vol. 5, pp. 264-271, March 2015.
                            </p>
                            <p>Rajaraman S, Chokkalingam A. Classification of Denver System of Chromosomes using
                                Similarity Classifier guided by OWA Operators. Current Bioinformatics, vol. 9, no. 5,
                                pp.
                                499-508, July 2014.
                            </p>
                            <p>Rajaraman S, Chokkalingam A. Performance Evaluation of Bio-Inspired Optimization
                                Algorithms in resolving Chromosomal Occlusions. Proceedings of the IEEE International
                                Conference on Control Instrumentation Communication and Computational Technologies
                                (ICCICCT 2014), pp. 57-64, Noorul Islam University, Kanyakumari, India, July 1– 11th
                                2014.
                            </p>
                            <p>Rajaraman S, Vaidyanathan G, Chokkalingam A. Performance Evaluation of Nature – Inspired
                                Optimization Techniques in Disentangling Text Pattern Overlaps. Journal of Multiple
                                valued
                                Logic and Soft Computing, vol. 23, no. 5-6, pp. 503-527, June 2014.
                            </p>
                            <p>Rajaraman S, Chokkalingam A. Occlusion Resolving in Text Patterns. Proceedings of the
                                International Conference on Emerging Trends in Science Engineering and Technology
                                (ICETSET
                                2014), pp. 197-201, Jerusalem College of Engineering, India, April 18th, 2014.
                            </p>
                            <p>Rajaraman S, Chokkalingam A. Lukaseiwicz logic based fuzzy similarity classifier for
                                Denver
                                group chromosomal classification. Biosci. J., Uberlandia, vol. 30, no. 3, pp. 843-852,
                                March
                                2014.
                            </p>
                            <p>
                                Rajaraman S, Chokkalingam A. Chromosomal Edge Detection using Modified Bacterial
                                Foraging Algorithm. International Journal of Bio-Science and Bio-Technology, vol. 6, no.
                                1, pp.
                                111-122, February 2014.

                            </p>
                            <p>Rajaraman S, Vaidyanathan G, Chokkalingam A. Segmentation and Removal of Interphase
                                Cells from Chromosome Images using Multidirectional Block Ranking. International Journal
                                of
                                Bio-Science and Bio-Technology, vol. 5, no. 3, pp. 79-92, June 2013.
                            </p>
                            <p>Rajaraman S, Chokkalingam A. Connected Components Labeling and Extraction Based
                                Interphase Removal from Chromosome Images. International Journal of Bio-Science and
                                Bio-Technology, vol. 5, no. 1, pp. 81-90, February 2013.
                            </p>
                        </section>
                    </div>
                </div>

            </div>
        </section>
        <hr class="m-0" />

        <!-- ------------------------ Interests ---------------------------->
        <section class="resume-section" id="global-interaction">
            <div class="resume-section-content">
                <h2 class="mb-5">Global Interaction (Past 3 years)</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Member of Technical Program Committee, 1st IEEE Life Sciences Conference
                            (LSC),
                            University of Technology, Sydney, Australia (13 - 15 December 2017).</div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2017</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Member of Organizing Committee, 4th International Conference on Bio signals,
                            Images, and
                            Instrumentation (ICBSII-2018), Dept. of Biomedical Engineering, SSN College of
                            Engineering, Kalavakkam, India (22- 24 March 2018)</div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Member of Technical Program Committee, International Conference on
                            Computational
                            Techniques, Electronics and Mechanical Systems (CTEMS’18)</div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Member of Technical Program Committee, Second International Conference on
                            Recent Trends
                            in Image Processing & Pattern Recognition (RTIP2R), Solapur University, Solapur,
                            Maharashtra state, India (21 - 22 December 2018).</div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Member of Technical Program Committee, International Conference On Image,
                            Video
                            Processing And Artificial Intelligence, organized by the Shanghai Advanced Research
                            Institute, Chinese Academy of Sciences, Shanghai, China (15 – 17 August 2018).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Member of Technical Program Committee, International Conference on Big Data
                            and
                            Artificial Intelligence (ICBDAI2018), organized by Ningbo Dahongying University and
                            International Association of Applied Science and Engineering Technology (IAAST) at
                            Ningbo, Zhejiang, China (21-23 December 2018)
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Member of Technical Program Committee, International Conference on
                            Electrical,
                            Communication, Electronics, Instrumentation and Computing (ICECEIC), organized by Sri
                            Chandrasekharendra Saraswathi Viswa Mahavidyalaya, Sri Jayendra Saraswathi Street,
                            Enathur, Kanchipuram, Tamil Nadu, India (30 – 31 January 2019).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2019</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Member of Technical Program Committee, Second International Conference On
                            Image, Video
                            Processing And Artificial Intelligence, organized by the Shanghai Advanced Research
                            Institute, Chinese Academy of Sciences, Shanghai, China (23 – 25 August 2019).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2019</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">9 Member of Technical Program Committee, 3rd International Conference on
                            Computer Science
                            and Application Engineering (CSAE 2019) to be held during October 22 to 24, 2019 in Sanya,
                            China.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2019</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">9Member of Technical Program Committee, International Conference on
                            Ubiquitous Intelligent
                            Systems (ICUIS 2020) to be held during 3-4, June 2020 in Shree Venkateshwara Hi-Tech
                            Engineering College, Tamil Nadu, India.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2019</span></div>
                </div>
            </div>
        </section>
        <hr class="m-0" />
        
        <!--------------------------- Awards ------------------------------->
        <section class="resume-section" id="awards">
            <div class="resume-section-content">
                <h2 class="mb-5">Honors and Awards</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">IEEE best project award with $500 cash prize from AT&T Bell Laboratories,
                            USA.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2000</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Best outgoing student award from PSNA College of Engineering and Technology,
                            Dindigul, India.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2001</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Best Teacher Award in the Dept. of Biomedical Engineering from SSN College of
                            Engineering, Kalvakkam, India.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2016</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Recipient of the Special Act or Service (SAS) group award in Clinical Image
                            Analysis,
                            awarded by the National Library of Medicine, National Institutes of Health, USA.

                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Recipient of a $500 spot award for the best employer showing dedication in
                            leading
                            significant advances in deep learning for clinical image analysis from Medical Science
                            & Computing, LLC.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Outstanding contribution in reviewing by Elsevier Computers and Electrical
                            Engineering journal in recognition of the contributions made to the quality of the
                            journal.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Outstanding contribution in reviewing by Elsevier Neurocomputing journal in
                            recognition of the contributions made to the quality of the journal.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
            </div>
        </section>
        <hr class="m-0" />


        <!--------------------------- Training courses and certifications ------------------------------->
        <section class="resume-section" id="training-certification">
            <div class="resume-section-content">
                <h2 class="mb-5">Training courses and certifications</h2>
                <table class="table">
                    <tr>
                        <th>Year</th>
                        <th>Course</th>
                        <th>Offered by</th>
                    </tr>
                    <tr>
                        <td>2020</td>
                        <td>Excel 2016 formulas</td>
                        <td>Computer training program, Centre for information  technology, National Institutes of Health (NIH), Bethesda,Maryland, USA</td>
                    </tr>
                    <tr>
                        <td>2020</td>
                        <td>Excel 2016 Pivot tables</td>
                        <td>-DO-</td>
                    </tr>
                    <tr>
                        <td>2020</td>
                        <td>Excel 2016 data analysis</td>
                        <td>-DO-</td>
                    </tr>
                    <tr>
                        <td>2020</td>
                        <td> Microsoft Outlook tips and tricks</td>
                        <td>-DO-</td>
                    </tr>
                    <tr>
                        <td>2020</td>
                        <td> Excel 2016 database features</td>
                        <td>-DO-</td>
                    </tr>
                    <tr>
                        <td>2020</td>
                        <td>NIH Anti-harassment training</td>
                        <td>NIH Office of Equity, Diversity, and Inclusion, NIH,Bethesda, Maryland, USA</td>
                    </tr>
              
                    <tr>
                        <td>2020</td>
                        <td>NIH Coronavirus Safety Guidance</td>
                        <td>NIH Learning Management System (LMS), NIH, Bethesda, Maryland, USA</td>
                    </tr>
                    <tr>
                        <td>2019</td>
                        <td>NIH Anti-harassment training</td>
                        <td>NIH Office of Equity, Diversity, and Inclusion, NIH,Bethesda, Maryland, USA</td>
                    </tr>
                    <tr>
                        <td>2019</td>
                        <td>NIH online technology transfer  training</td>
                        <td>NIH Learning Management System (LMS), NIH, Bethesda, Maryland, USA</td>
                    </tr>
                    <tr>
                        <td>2018</td>
                        <td>NIH online technology transfer training</td>
                        <td>NIH Learning Management System (LMS), NIH, Bethesda,Maryland, USA</td>
                    </tr>
                    <tr>
                        <td>2018</td>
                        <td>NIH Continuity of operations training</td>
                        <td>NIH Office Of Management (OOM), NIH, Bethesda, Maryland, USA</td>
                    </tr>
                    <tr>
                        <td>2018</td>
                        <td>Introduction to Data Science with Python</td>
                        <td>DataCamp E-Learning, New York, USA</td>
                    </tr>
                    <tr>
                        <td>2017</td>
                        <td>CANcer Distributed Learning  Environment (CANDLE)</td>
                        <td>National Cancer Institute (NCI) and the Department of Energy (DOE), NIH, Bethesda, Maryland, USA</td>
                    </tr>
                    <tr>
                        <td>2017</td>
                        <td>NIH online technology transfer  training</td>
                        <td>NIH Learning Management System (LMS), NIH, Bethesda,Maryland, USA</td>
                    </tr>
              
                    <tr>
                        <td>2001</td>
                        <td>Postgraduate diploma in computer applications (PGDCA)</td>
                        <td>National Institute of Information Technology (NIIT), India</td>
                    </tr>
              

                </table>
            </div>
        </section>
        <hr class="m-0" />
        <!--------------------------- Editorial Board Positions ------------------------------->
        <section class="resume-section" id="editorial-pos">
            <div class="resume-section-content">
                <h2 class="mb-5">Editorial Board Positions</h2>
                <table class="table">
                    <tr>
                        <th>Name of the Journal</th>
                        <th>Publisher</th>
                    </tr>
                    <tr>
                        <td>Electronics (Web of Science IF: 2.412) (Topics Board)</td>
                        <td>Multidisciplinary Digital Publishing Institute (MDPI), Switzerland</td>
                    </tr>
                    <tr>
                        <td>American Journal of Neural Networks and Applications</td>
                        <td>Science Publishing Group, USA</td>
                    </tr>
                    <tr>
                        <td>Artificial intelligence research journal</td>
                        <td>Bio-Byword Scientific Publishing, Australia</td>
                    </tr>

                </table>
            </div>
        </section>
        <hr class="m-0" />

        <!--------------------------- Reviewer Positions ------------------------------->
        <section class="resume-section" id="reviewer-pos">
            <div class="resume-section-content">
                <h2 class="mb-5">Reviewer Positions</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Placed in the top 1% of reviewers consecutively on Publons’ global reviewer database for the
                            award years 2017-19 and 2018-19. This award is determined by the number of peer review
                            reports performed during the given award year.
                            Serving as a reviewer for the National Science Foundation (NSF) Graduate Research Fellowship
                            Program (GRFP). NSF-GRFP is a prestigious grant awarded annually by the NSF to students
                            pursuing research-based Master's and doctoral degrees in the natural, social, and engineering
                            sciences at US institutions.
                            Reviewing manuscripts for several leading journals some of which are mentioned below:
                        </div>
                    </div>
                </div>
                <table class="table">
                    <tr>
                        <th>Name of the Journal</th>
                        <th>Publisher</th>
                    </tr>
                    <tr>
                        <td>The LANCET Digital Health</td>
                        <td>The LANCET</td>
                    </tr>
                    <tr>
                        <td>Scientific Reports</td>
                        <td>Nature journals</td>
                    </tr>
                    <tr>
                        <td>Digital Medicine </td>
                        <td>Nature journals</td>
                    </tr>
                    <tr>
                        <td>PLOS Neglected Tropical Diseases</td>
                        <td>PLOS</td>
                    </tr>
                    <tr>
                        <td>ACM Transactions on Multimedia Computing, Communications and  Applications  </td>
                        <td>ACM</td>
                    </tr>
                    <tr>
                        <td>ACM Transactions on Management Information Systems</td>
                        <td>ACM</td>
                    </tr>
                    <tr>
                        <td>International Journal of Urology</td>
                        <td>Wiley Online Library</td>
                    </tr>
                    <tr>
                        <td>Concurrency and Computation: Practice and Experience </td>
                        <td>Wiley Online Library</td>
                    </tr>
                    <tr>
                        <td>Expert Systems </td>
                        <td>Wiley Online Library</td>
                    </tr>
                    <tr>
                        <td>International Journal for Numerical Methods in Biomedical Engineering </td>
                        <td>Wiley Online Library</td>
                    </tr>
                    <tr>
                        <td>International Journal of Imaging Systems and Technology</td>
                        <td>Wiley Online Library</td>
                    </tr>
                    <tr>
                        <td>Journal of Clinical Laboratory Analysis</td>
                        <td>Wiley Online Library</td>
                    </tr>
                    <tr>
                        <td>Rapid Reviews: COVID-19 (RR: C19)</td>
                        <td>MIT Press and UC Berkeley</td>
                    </tr>
                    <tr>
                        <td>Nephrology</td>
                        <td>ASPN</td>
                    </tr>
                    <tr>
                        <td>Transactions on Fuzzy Systems</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>EEE/ACM Transactions on Computational Biology and Bioinformatics</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>IEEE Transactions on Radiation and Plasma Medical Sciences</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>IEEE Transactions on Cognitive and Developmental Systems</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Journal of Electromagnetics, RF, and Microwaves in Medicine and Biology</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Journal of Translational Engineering in Health and Medicine</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Transactions on Medical Imaging</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Transactions on Network Science and Engineering</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Access</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Journal of Biomedical And Health Informatics</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Sensors</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>IEEE Wireless Communications Magazine </td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Systems</td>
                        <td>IEEE</td>
                    </tr>
                    <tr>
                        <td>Biomedical Physics & Engineering Express</td>
                        <td>IOP</td>
                    </tr>
                    <tr>
                        <td>SciNotes</td>
                        <td>IOP</td>
                    </tr>
                    <tr>
                        <td>Annals of Saudi Medicine </td>
                        <td>ASM</td>
                    </tr>
                    <tr>
                        <td>BMC Malaria Journal</td>
                        <td>BioMed Central</td>
                    </tr>
                    <tr>
                        <td>BMC Medical Informatics and Decision Making </td>
                        <td>BioMed Central</td>
                    </tr>
                    <tr>
                        <td>BMC Medical Imaging</td>
                        <td>BioMed Central</td>
                    </tr>
                    <tr>
                        <td>Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization </td>
                        <td>Taylor & Francis</td>
                    </tr>
                    <tr>
                        <td>Journal of Biomolecular Structure and Dynamics </td>
                        <td>Taylor & Francis</td>
                    </tr>
                    <tr>
                        <td>Journal of Experimental & Theoretical Artificial Intelligence</td>
                        <td>Taylor & Francis</td>
                    </tr>
                    <tr>
                        <td>Information Fusion</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Industrial Crops & Products</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Results in Physics</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Applied Soft Computing</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Biomedical Signal Processing and Control</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Measurement</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Pattern Recognition Journal</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Translational Research</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Computers and Electronics in Agriculture</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Computers in Biology and Medicine </td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Neurocomputing </td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>Computers and Electrical Engineering</td>
                        <td>Elsevier</td>
                    </tr>
                    <tr>
                        <td>SLAS Technology</td>
                        <td>SAGE</td>
                    </tr>
                    <tr>
                        <td>The Open Biomedical Engineering Journal</td>
                        <td>Bentham Science</td>
                    </tr>
                    <tr>
                        <td>Processes</td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Symmetry</td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Brain Sciences </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Healthcare </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Diagnosis </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Machine Learning and Knowledge Extraction  </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Applied Sciences  </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Algorithms </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Materials </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Children </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Electronics </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Processes </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Mathematics </td>
                        <td>MDPI</td>
                    </tr>
                    <tr>
                        <td>Journal of Intelligent Systems </td>
                        <td>De Gruyter</td>
                    </tr>
                    <tr>
                        <td>International Journal of Applied Mathematics and Computer Sciences</td>
                        <td>De Gruyter</td>
                    </tr>
                    <tr>
                        <td>International Journal of Machine Learning and Cybernetics</td>
                        <td>Springer</td>
                    </tr>
                    <tr>
                        <td>Multimedia Tools and Applications</td>
                        <td>Springer</td>
                    </tr>
                    <tr>
                        <td>Journal of Medical Systems</td>
                        <td>Springer</td>
                    </tr>
                    <tr>
                        <td>European Journal of Nuclear Medicine and Molecular Imaging.</td>
                        <td>Springer</td>
                    </tr>
                    <tr>
                        <td>IET Journal of Research.</td>
                        <td>IET</td>
                    </tr>
                    <tr>
                        <td>International Journal of Engineering Research and Technology</td>
                        <td>IRP House</td>
                    </tr>
                    <tr>
                        <td>ELECTRICA</td>
                        <td>İstanbul University-Cerrah paşa Faculty of Engineering</td>
                    </tr>
                </table>

            </div>
        </section>
        <hr class="m-0" />


        <!--------------------------- Mentoring and extra-curricular activities ------------------>
        <section class="resume-section" id="mentoring">
            <div class="resume-section-content">
                <h2 class="mb-5">Mentoring and extra-curricular activities</h2>

                <div class="flex-grow-1">
                  <p>Mentored students at the undergraduate and postgraduate levels in electronics, communication,
                    and biomedical engineering discipline.
                    </p>
                    <p>Guided several projects at the undergraduate and postgraduate levels.
                        Organized several workshops, seminars, and faculty development programs, national and
                        international conferences.
                    </p>
                    <p>Served as a senior member in several institutional accreditation committees including National
                        Board of Accreditation (NBA) and National Assessment and Accreditation Council (NAAC)</p>
                </div>

            </div>
        </section>
        <hr class="m-0" />

        
        <!---------------------------- presentations ------------------------>

        <section class="resume-section" id="presentations">
            <div class="resume-section-content">
                <h2 class="mb-5">Presentations</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Invited Speaker, ISTE - SRM - STTP on Soft Computing Techniques for Clinical
                            Decision
                            Making, Dept. of Biomedical Engineering, PSNA College of Engineering and Technology,
                            Dindigul, India, July 2014.
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2014</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Improving karyotyping by removing interphases from chromosomal
                            images.
                            Presented at the US National Library of Medicine (NLM) Brown Bag Lecture Series Talk,
                            LHNCBC, US National Library of Medicine, NIH. (January 24, 2017).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2017</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Deep Learning Model Comparisons. Presented at the US National
                            Library of
                            Medicine (NLM) CEB/CSB presentations to NLM Associate Fellows Talk, LHNCBC, US
                            National Library of Medicine, NIH. (June 20, 2017).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2017</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">RRajaraman, S. Visualizing salient network activations in a custom Deep
                            Learning model
                            towards improved malaria cell classification. Presented at the US National Library of
                            Medicine (NLM) Fellowship Series Talk, LHNCBC, US National Library of Medicine, NIH.
                            (August 30, 2017).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2017</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Stacked Generalization of DL models for Malaria Parasite
                            Detection. Presented
                            at the US National Library of Medicine (NLM) Deep Learning Research Interest Group Series
                            Talk, LHNCBC, US National Library of Medicine, NIH. (October 5, 2017).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2017</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Visualizing Deep Learning Activations. Presented at the US
                            National Library of
                            Medicine (NLM) CEB/CSB presentations to NLM Associate Fellows Talk, LHNCBC, US
                            National Library of Medicine, NIH. (October 18, 2017).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2017</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Principles of Deep Learning and its application in medical
                            image processing.
                            Presented at the US National Library of Medicine (NLM) Briefings for the CEB Externs Talk,
                            LHNCBC, US National Library of Medicine, NIH. (January 18, 2018).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Deep Learning for Malaria Screening. Presented at the US
                            National Library of
                            Medicine (NLM) Brown Bag Lecture Series Talk, LHNCBC, US National Library of
                            Medicine, NIH. (March 20, 2018).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Deep Learning: What is it? Presented at the US National Library
                            of Medicine
                            (NLM) CEB/CSB presentations to Summer Interns, LHNCBC, US National Library of
                            Medicine, NIH. (June 20, 2018).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Visualizing and explaining deep learning predictions for
                            pneumonia detection in
                            pediatric chest radiographs. Presented a poster at the NIH Research (September 13, 2018).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <div class=" mb-3">Rajaraman, S. Deep Learning and its application in Chest X-ray Screening,
                            Presented at the
                            US National Library of Medicine (NLM) CEB/CSB presentations to Summer Interns,
                            LHNCBC, US National Library of Medicine, NIH. (June 25, 2019).
                        </div>
                    </div>
                    <div class="flex-shrink-0 row__year"><span class="text-primary">2018</span></div>
                </div>
            </div>
        </section>
        <hr class="m-0" />
        <!----------------------------- publications ------------------------->
        <section class="resume-section" id="publications">
            <div class="resume-section-content">
                <h2 class="mb-5">Publications</h2>
                <div class="flex-grow-1 mb-5">
                    <h3>Peer-reviewed Journals (Most recent)</h3>
                    <div class="flex-grow-1">
                        <p> <b>Rajaraman S, </b> (Most recent)
                            Rajaraman S, Candemir S, Xue Z, Alderson P, Thoma G, Antani SK. In Santosh KC et al.
                            (Eds.). Medical Imaging: Artificial Intelligence, Image Recognition, and Machine Learning
                            Techniques. (pp. 1-26). New York, NY: CRC Press, Taylor & Francis Group.
                        </p>
                        <p> <b>Rajaraman S, </b> Jaeger S, Antani SK. (2019) Performance evaluation of deep neural
                            ensembles
                            toward malaria parasite detection in thin-blood smear images. PeerJ 7:e6977
                            https://doi.org/10.7717/peerj.6977.
                        </p>
                        <p>Kim I, <b>Rajaraman, S </b>Antani S. Visual Interpretation of Convolutional Neural Network
                            Predictions in Classifying Medical Image Modalities. MDPI Diagnostics 2019, 9, 38.
                        </p>
                        <p> <b>Rajaraman S, </b> Candemir S, Kim I, Thoma GR, Antani SK. Visualization and
                            Interpretation of
                            Convolutional Neural Network Predictions in Detecting Pneumonia in Pediatric Chest
                            Radiographs. Appl. Sci. 2018, 8, 1715.
                        </p>
                        <p>Thamizhvani TR, Lakshmanan <b>Rajaraman S, </b>Mobile application-based computer-aided
                            diagnosis of skin tumours from dermal images, The Imaging Science Journal, 66:6, 382-391,
                            2018, DOI: 10.1080/13682199.2018.1492682.

                        </p>
                        <p><b>Rajaraman S, </b> Silamut K, Hossain MA, Ersoy I, Maude RJ, Jaeger S, Thoma GR, Antani SK.
                            Understanding the learned behavior of customized convolutional neural networks toward
                            malaria
                            parasite detection in thin blood smear images. J. Med. Imag. 5(3), 034501 (2018), doi:
                            10.1117/1.JMI.5.3.034501.
                        </p>
                        <p><b>Rajaraman S, </b>Antani SK, Poostchi Mohammadabadi M, Silamut K, Hossain MA, Maude RJ,
                            Jaeger S, Thoma GR. (2018) Pre-trained convolutional neural networks as feature extractors
                            toward improved malaria parasite detection in thin blood smear images. PeerJ6:e4568
                            https://doi.org/10.7717/peerj.4568.

                        </p>
                    </div>

                </div>
                <div class="flex-grow-1 mb-5">
                    <h3>Peer-reviewed Conferences (Most recent)</h3>
                    <div class="flex-grow-1">
                        <p>Ganesan P, <b>Rajaraman S, </b> S, Long LR, Ghoraani B, Antani SK. Assessment of Data
                            Augmentation
                            Strategies Toward Performance Improvement of Abnormality Classification in Chest
                            Radiographs. Proc. IEEE Engineering in Medicine and Biology Conference (EMBC), Berlin,
                            Germany, 23 – 27 July 2019. pp. 841 – 844.

                        </p>
                        <p> <b>Rajaraman S, </b> , Sornapudi S, Kohli M, Antani SK. Assessment of an ensemble of machine
                            learning models toward abnormality detection in chest radiographs. Proc. IEEE Engineering in
                            Medicine and Biology Conference (EMBC), Berlin, Germany, 23 – 27 July 2019. pp. 3689 –
                            3692.

                        </p>
                        <p><b>Rajaraman, S </b>Antani S. (2019) Visualizing Salient Network Activations in Convolutional
                            Neural Networks for Medical Image Modality Classification. In: Santosh K., Hegadi R. (eds)
                            Recent Trends in Image Processing and Pattern Recognition. RTIP2R 2018. Communications in
                            Computer and Information Science, vol. 1036. Springer, Singapore. DOI:
                            https://doi.org/10.1007/978-981-13-9184-2_4

                        </p>
                        <p> <b>Rajaraman S, </b>, Candemir S, Thoma G, Antani S. Visualizing and explaining deep
                            learning
                            predictions for pneumonia detection in pediatric chest radiographs, Proc. SPIE 10950,
                            Medical
                            Imaging 2019: Computer-Aided Diagnosis, 109500S (13 March 2019); doi: 10.1117/12.2512752.
                            Candemir S, <b>Rajaraman S,</b> Thoma GR, Antani SK. Deep Learning for Grading Cardiomegaly
                            Severity in Chest X-rays: An Investigation. Proc. IEEE Life Sciences Conference (LSC 2018),
                            Montreal, Quebec, Canada, 28 – 30 October 2018. pp. 109-113.

                        </p>
                    </div>
                </div>
            </div>
        </section>
        <hr class="m-0" />
        <!-- --------------------------- References ------------------------->
        <section class="resume-section align-top" id="references">
            <div class="resume-section-content">
                <h2 class="mb-5">References</h2>
                <section class="row no-gutters">
                    <address class="flex-grow-1 mb-5">
                        <h4>Dr. George R. Thoma</h4>
                        Chief (Ret.) Communications Engineering Branch,<br>
                        Lister Hill National Center for Biomedical<br>
                        Communications,<br>
                        National Library of Medicine,<br>
                        Rockville Pike, Bethesda, MD 20894 USA<br>
                        Phone: (301) – 496 - 4496<br>
                        Email address: gthoma@mail.nih.gov<br>
                    </address>
                    <address class="flex-grow-1 mb-5">
                        <h4>Dr. Sameer K. Antani,</h4>
                        Chief, Communications Engineering Branch,<br>
                        Lister Hill National Center for Biomedical<br>
                        Communications,<br>
                        National Library of Medicine,<br>
                        Rockville Pike, Bethesda, MD 20894 USA<br>
                        Phone: (301) – 435 - 3218<br>
                        Email address:santani@mail.nih.gov<br>
                    </address>
                </section>
                <section class="row no-gutters">
                    <address class="flex-grow-1 mb-5">
                        <h4>Dr. Arun Chokkalingam, </h4>
                        Professor,<br>
                        Dept. of Electronics and Commn. Eng.,<br>
                        RMK College of Engineering and Technology,<br>
                        puduvoyal, chennai, Tamilnadu, India ,<br>
                        Phone: +91-9843506892<br>
                        Email Address: carunece@gmail.com
                    </address>
                    <address class="flex-grow-1 mb-5">
                        <h4>Dr. Chandrasekar Garlapati,</h4>
                        Professor & Head,<br>
                        Department of Chemical Engineering,<br>
                        Pondichery Engineering College,<br>
                        Pondichery-605014, India<br>
                        Phone: +91-9698982254,<br>
                        Email Address: chandrasekar@pec.edu<br>
                    </address>
                </section>
            </div>
        </section>
        <hr class="m-0" />


    </div>
    <!-- Bootstrap core JS-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Third party plugin JS-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>

</html>
